{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgw1442gA3zA"
      },
      "source": [
        "# **Final Data Science Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4e2YyHvGL3"
      },
      "source": [
        "## **Project Details**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCut0fjByTxT"
      },
      "source": [
        "\n",
        "**Subject:** Nature Reserve Sites In Israel.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Target:** Predict Sites Entries, Present Recommendations and Information.\n",
        "\n",
        "---\n",
        "\n",
        "**Models:** Clustering, Neural Networks, Linear Regressions.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Instructions:** Run all cells, and start the main section. models and output can be saved and uploaded on colab and then downloaded manually(after saving file with the interface, go to the left tab and download file, this file can later be uploaded and integrated on this project) to your PC for faster future predictions.\n",
        "This project is made for the long run, any future data additions will work, although feature names should not be altered.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Made by:** Tal Golan.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPYp3erkvQH"
      },
      "source": [
        "## Dictionaries Declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nS24l8Wz0TKM"
      },
      "outputs": [],
      "source": [
        "global MLRs, NN, Clustering,Model_Index,Run_Check\n",
        "MLRs={}\n",
        "NNs={}\n",
        "Clustering={}\n",
        "Run_Check=0\n",
        "Model_Index=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvOn3ylhlLg7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clRK07meVeLF",
        "outputId": "f7eeda19-0d6f-463c-c2b5-cfea09f66ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (37.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kneed in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kneed) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kneed) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->kneed) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->kneed) (1.15.0)\n",
            "/bin/bash: matplotlib: command not found\n"
          ]
        }
      ],
      "source": [
        "#Imports\n",
        "from google.colab import files  \n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from threading import Timer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import *\n",
        "from statistics import mean\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from IPython.display import clear_output \n",
        "import sys, os\n",
        "import keras\n",
        "keras.__version__\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from logging import warning\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "import json, requests, urllib, io\n",
        "!pip install cryptography\n",
        "from cryptography.fernet import Fernet\n",
        "!pip install kneed\n",
        "from kneed import KneeLocator\n",
        "!matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGPO15-glrZG"
      },
      "source": [
        "## Uploading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A-KO8ocwmLyO"
      },
      "outputs": [],
      "source": [
        "# Getting data. \n",
        "global dfc # Clustering\n",
        "global df # MLRs,NNs\n",
        "global pao #personal token\n",
        "def Main_Project():\n",
        "  global df,pao,dfc_info\n",
        "  user='talfx'\n",
        "  pao='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'\n",
        "\n",
        "  github_session = requests.Session()\n",
        "  github_session.auth = (user, pao)\n",
        "\n",
        "  # providing raw url to download csv from github\n",
        "  csv_url1 = 'https://raw.githubusercontent.com/talfx/Final-Project/7d7e68b469e2fb8b8b99196df683c28329f43e23/df_Daily1.csv'\n",
        "  csv_url2 = 'https://raw.githubusercontent.com/talfx/Final-Project/7d7e68b469e2fb8b8b99196df683c28329f43e23/df_Daily2.csv'\n",
        "  csv_url3 = 'https://raw.githubusercontent.com/talfx/Final-Project/7d7e68b469e2fb8b8b99196df683c28329f43e23/df_info.csv'\n",
        "\n",
        "  download1 = github_session.get(csv_url1).content\n",
        "  downloaded_csv1 = pd.read_csv(io.StringIO(download1.decode('utf-8')))\n",
        "  download2 = github_session.get(csv_url2).content\n",
        "  downloaded_csv2 = pd.read_csv(io.StringIO(download2.decode('utf-8')))\n",
        "  download3 = github_session.get(csv_url3).content\n",
        "  downloaded_csv3 = pd.read_csv(io.StringIO(download3.decode('utf-8')))\n",
        "  df=pd.concat([downloaded_csv1,downloaded_csv2]).reset_index()\n",
        "  dfc_info=downloaded_csv3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vwotGiJlyRa"
      },
      "source": [
        "## Global Data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZwAaAiu6nd-N"
      },
      "outputs": [],
      "source": [
        "def Change_Names_Spaces(Some_df,feature):\n",
        "    Some_df[feature] = Some_df[feature].str.replace(' ', '_',regex=True)\n",
        "    Some_df[feature] = Some_df[feature].str.replace('-', '_',regex=True)\n",
        "    Some_df[feature] = Some_df[feature].str.replace(\"_â€“_\", '_',regex=True)\n",
        "    Some_df[feature] = Some_df[feature].str.replace('(', '',regex=True)\n",
        "    Some_df[feature] = Some_df[feature].str.replace(')', '',regex=True)\n",
        "    return Some_df\n",
        "def Starting_Data_Prep_Main():\n",
        "  global df,dfc,dfc_info\n",
        "  \n",
        "  df['Date']= pd.to_datetime(df['Date'],format=\"%Y/%m/%d\")\n",
        "  df=Change_Names_Spaces(df,'Site_Name')\n",
        "  dfc_info=Change_Names_Spaces(dfc_info,'Site_Name')\n",
        "  df['pm10'].fillna(value=df['pm10'].mean(), inplace=True)\n",
        "  df['pm2.5'].fillna(value=df['pm2.5'].mean(), inplace=True)\n",
        "  df['nox'].fillna(value=df['nox'].mean(), inplace=True)\n",
        "  df['so2'].fillna(value=df['so2'].mean(), inplace=True)\n",
        "\n",
        "        \n",
        "pd.set_option('display.max_columns', None)\n",
        "class bcolors:\n",
        "    GREEN = '\\033[92m' #GREEN\n",
        "    YELLOW = '\\033[93m' #YELLOW\n",
        "    RED = '\\033[91m' #RED\n",
        "    RESET = '\\033[0m' #RESET COLOR\n",
        "    CYAN= '\\033[96m' #CYAN \n",
        "    HEADER='\\033[95m' #HEADER\n",
        "    BLUE='\\033[94m' #BLUE\n",
        "    \n",
        "def Orginize_OutPut(old_df):\n",
        "  new_df=old_df.copy()\n",
        "  arr=[]\n",
        "  arr2=[old_df.columns[-3],old_df.columns[-2],old_df.columns[-1]]\n",
        "  for item in arr2:\n",
        "    arr.append(item)\n",
        "  for item in new_df.columns[:-3]:\n",
        "    arr.append(item)\n",
        "  print(new_df[arr].round(2).head().to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbEtfKipl8u3"
      },
      "source": [
        "# **Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SJgsoz3l_0D"
      },
      "source": [
        "## Choosing Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2XeCoNd2mhVs"
      },
      "outputs": [],
      "source": [
        "#Choosing which features to cluster, taking means for features that change daily\n",
        "def choice():\n",
        "  global dfc5,dfc,dfc_info,df\n",
        "  dfc5=df.copy()\n",
        "  dfc_info=dfc_info.groupby('Site_Name').mean()\n",
        "  dfc5=dfc5.groupby('Site_Name').mean()\n",
        "  dfc5.drop(['index','Unnamed: 0','Unnamed: 0'], axis=1, inplace=True)\n",
        "  dfc_info.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "  dfc=dfc5.join(dfc_info)\n",
        "  dfc5=dfc.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zQ_mtFlmKyi"
      },
      "source": [
        "##Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xyQwybyNmhTF"
      },
      "outputs": [],
      "source": [
        "#Cluster scaling, saved seperately from MLRs and NNs\n",
        "def ClusterScale():\n",
        "  global scalerc,scaled_dfc,dfc\n",
        "  scalerc = StandardScaler()\n",
        "  scalerc.fit(dfc)\n",
        "  scaled_dfc = pd.DataFrame(scalerc.transform(dfc), columns=dfc.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9zLthpvmO7h"
      },
      "source": [
        "## Elbow Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DCJtLQIUmhQh"
      },
      "outputs": [],
      "source": [
        "#Elbow Test, choosing the best value visually\n",
        "def ElbowTest():\n",
        "  global scaled_dfc,sse\n",
        "  sse = []\n",
        "  if len(scaled_dfc)<3:\n",
        "    return False\n",
        "  k=3\n",
        "  while 1:\n",
        "    km = KMeans(n_clusters=k, random_state=1234)\n",
        "    km.fit(scaled_dfc)\n",
        "    if(km.inertia_==0):\n",
        "      break\n",
        "    k+=1\n",
        "      \n",
        "    sse.append(km.inertia_)\n",
        "  \n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter( y=sse, mode='markers+lines'))\n",
        "  fig.update_layout(\n",
        "      title=\"Elbow Test\",\n",
        "      xaxis_title=\"K\",\n",
        "      yaxis_title=\"Inertia\",\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=14,\n",
        "          color=\"RebeccaPurple\"\n",
        "      ),\n",
        "      width=800\n",
        "  )\n",
        "\n",
        "  fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35VLIevnmSjO"
      },
      "source": [
        "## silhouette Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PqRvj022mhJy"
      },
      "outputs": [],
      "source": [
        "#Closer to 1 --> the clusers are further apart\n",
        "# (b - a) / max(a, b) \n",
        "#  b is the distance between a sample and the nearest other clusters, for each point\n",
        "\n",
        "def SillTest():\n",
        "  global dfc,scaled_dfc,sil\n",
        "  sil = []\n",
        "  k=2\n",
        "  if len(dfc)<3:\n",
        "    return False\n",
        "\n",
        "  kmeans = KMeans(n_clusters=len(dfc)-1,random_state=1234).fit(scaled_dfc)\n",
        "  labels = kmeans.labels_\n",
        "  \n",
        "  score3=silhouette_score(scaled_dfc, labels, metric = 'euclidean')\n",
        "  score2=score3\n",
        "  \n",
        "   \n",
        "  for i in range(0, len(dfc)-3) :\n",
        "    kmeans = KMeans(n_clusters=k,random_state=1234).fit(scaled_dfc)\n",
        "    labels = kmeans.labels_\n",
        "    score1=silhouette_score(scaled_dfc, labels, metric = 'euclidean')\n",
        "    \n",
        "    if score1==score2 and score1==score3:\n",
        "      break\n",
        "    k+=1\n",
        "    sil.append(score1)\n",
        "    score2=sil[-1]\n",
        "    if k>=4:\n",
        "     score3=sil[-2]\n",
        "\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(y=sil, mode='markers+lines'))\n",
        "  fig.update_layout(\n",
        "      title=\"Sillhouette Test\",\n",
        "      xaxis_title=\"K\",\n",
        "      yaxis_title=\"Inertia\",\n",
        "\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=14,\n",
        "          color=\"RebeccaPurple\"\n",
        "      ),\n",
        "      width=800\n",
        "  )\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzmmz9JymaoP"
      },
      "source": [
        "## Clustering Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qMsiu469mhG-"
      },
      "outputs": [],
      "source": [
        "#Starting Clustering and saving results in a list\n",
        "def Cluster():\n",
        "  global cluster_means,K_means,Clusters_List,labels,dfc,dfcc\n",
        "  kmeans = KMeans(n_clusters=K_means, random_state=1234)\n",
        "  kmeans.fit_predict(scaled_dfc)\n",
        "  kmeans.cluster_centers_\n",
        "  \n",
        "  labels = kmeans.labels_\n",
        "  \n",
        "  dfc['cluster'] = labels\n",
        "  \n",
        "  cluster_means = dfc.groupby('cluster').mean() \n",
        "  \n",
        "  cluster_centers = scalerc.inverse_transform(kmeans.cluster_centers_)\n",
        "  \n",
        "  dfcc=dfc.copy()\n",
        "  dfcc['SiteName'] = dfc.index\n",
        "  dfcc = dfcc.rename_axis('index1').reset_index()\n",
        "  \n",
        "  dfcc = pd.crosstab([dfcc.cluster, dfcc.SiteName], 0, margins=True)\n",
        "  i=0\n",
        "  \n",
        "  Cluster_List=[]\n",
        "  Clusters_List=[]\n",
        "  \n",
        "  for index, row in dfcc.iterrows():\n",
        "    if index[0] is not 'All':\n",
        "      if float(index[0])>i:\n",
        "        i+=1\n",
        "        Clusters_List.append(Cluster_List)\n",
        "        Cluster_List=[]\n",
        "      Cluster_List.append(index[1])\n",
        "      \n",
        "  Clusters_List.append(Cluster_List)\n",
        "def Cluster_by():\n",
        "  \n",
        "  global cluster_means,K_means,Clusters_List,labels,dfc,scaled_dfc\n",
        "  kmeans = KMeans(n_clusters=K_means, random_state=1234)\n",
        "  kmeans.fit_predict(scaled_dfc)\n",
        "  kmeans.cluster_centers_\n",
        "  \n",
        "  labels = kmeans.labels_\n",
        "  \n",
        "  dfc['cluster'] = labels\n",
        "  \n",
        "  cluster_means = dfc.groupby('cluster').mean() \n",
        "  \n",
        "  cluster_centers = kmeans.cluster_centers_\n",
        "  dfc['Target'] = dfc.index\n",
        "  dfc = pd.crosstab([dfc.cluster, dfc.Target], 0, margins=True)\n",
        "  Cluster_List=[]\n",
        "  Clusters_List=[]\n",
        "  i=0\n",
        "  for index, row in dfc.iterrows():\n",
        "    if index[0] is not 'All':\n",
        "      if float(index[0])>i:\n",
        "        i+=1\n",
        "        Clusters_List.append(Cluster_List)\n",
        "        Cluster_List=[]\n",
        "      Cluster_List.append(index[1])\n",
        "      \n",
        "  Clusters_List.append(Cluster_List)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csZPvDiympXN"
      },
      "source": [
        "## Clustering Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CmBo20tTnyK4"
      },
      "outputs": [],
      "source": [
        "# Clustering Details\n",
        "\n",
        "def Clustering_Model_Details():\n",
        "  global Clusters_List,cluster_means,labels,K_means,dfc,cluster_stds\n",
        "  count=dfc['cluster'].value_counts()\n",
        "  cluster_stds = dfc.groupby('cluster').std() \n",
        "  cluster_stds.fillna(0, axis=1,inplace=True)\n",
        "  \n",
        "  print(\"----------------Sites Clustered---------------- \\n\")\n",
        "  for i in Clusters_List:\n",
        "    print(i)\n",
        "  print(\"----------------K-means---------------- \\n\",K_means)\n",
        "  print(\"----------------Cluster Labels---------------- \\n\",labels)\n",
        "  print(\"----------------Cluster Count---------------- \\n\",count)\n",
        "  print(\"----------------Cluster Means---------------- \\n\",cluster_means.round(2).to_markdown())\n",
        "  print(\"----------------Cluster STD---------------- \\n\",cluster_stds.round(2).to_markdown())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWy1EveSmwDI"
      },
      "source": [
        "## Find Sites Name in Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gYAzvRXwnyFl"
      },
      "outputs": [],
      "source": [
        "#Printing Recommendations: showing sites within the same cluster\\, and highligting which features mostly correlated\n",
        "\n",
        "def FindCluster(Name):\n",
        "  global Clusters_List\n",
        "  loc=0\n",
        "  c=0\n",
        "  arr=[]\n",
        "  for i in range(0,len(Clusters_List)):\n",
        "    \n",
        "    for j in range(0,len(Clusters_List[i])):\n",
        "      if Clusters_List[i][j]==Name:\n",
        "        loc=i\n",
        "        c=1\n",
        "        break\n",
        "    if c==1:\n",
        "      break\n",
        "\n",
        "  for i in range(0,len(Clusters_List[loc])):\n",
        "    if Clusters_List[loc][i]!=Name:\n",
        "      arr.append(Clusters_List[loc][i])\n",
        "  \n",
        "  return arr\n",
        "  \n",
        "def Print_Cluster_Info(arr,Name):\n",
        "  name_df=dfc.loc[Name]\n",
        "  print(\"--------------Our Recommendations:--------------\\n\")\n",
        "  print(\"------------Here are other sites you might be interested in! (Similar attributes are marked)------------\\n\")\n",
        "  for item in arr:\n",
        "    if item!=Name:\n",
        "      print(\"\\nSite Name: \",item )\n",
        "      Group_Item_df=dfc.loc[item]\n",
        "      for column in dfc.columns:\n",
        "        if ((name_df[column]==Group_Item_df[column] and Group_Item_df[column]==1) or\\\n",
        "            ((column=='Tourists_Count' or\\\n",
        "              column=='Israelis_Count' or column=='Total') and \\\n",
        "             (abs(name_df[column]-Group_Item_df[column]<20))  ) or\\\n",
        "            (column=='Temperature' and abs(name_df[column]-Group_Item_df[column]<5))) and column !='cluster' :\n",
        "          print(bcolors.GREEN,\" \",column,\": \", round(Group_Item_df[column],2), bcolors.RESET,end='')\n",
        "\n",
        "  print(\"\\n----------------------------------------------------------------------\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqwpqUo8fCoH"
      },
      "source": [
        "## Finding Optimal K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "taMgyQIHfAM1"
      },
      "outputs": [],
      "source": [
        "#Finding an optimal K-Means\n",
        "#plot \n",
        "def calc_distance_Point_To_Line(x1, y1, a, b, c):\n",
        "  d = abs((a * x1 + b * y1 + c)) / (math.sqrt(a * a + b * b))\n",
        "  return d\n",
        "#Calculated by creating a line and therfore finding the best K by the ElbowTest\n",
        "#Then taking %5 error rate to the left and right, and using the Sillhouette test to find the highest K-\n",
        "#within that error rate, therfore finding the best K mathematically.\n",
        "def Optimal_K():\n",
        "  global sse,K_Means_All,sil\n",
        "  K_Means_All=range(3,len(scaled_dfc))\n",
        "  a = sse[0] - sse[-1]\n",
        "  b = K_Means_All[-1] - K_Means_All[0]\n",
        "  c1 = K_Means_All[0] * sse[-1]\n",
        "  c2 = K_Means_All[-1] * sse[0]\n",
        "  c = c1 - c2\n",
        "  distance_of_points_from_line = []\n",
        "  for k in range(len(K_Means_All)):\n",
        "    distance_of_points_from_line.append(calc_distance_Point_To_Line(K_Means_All[k], sse[k], a, b, c))\n",
        "  OptimalElbow=distance_of_points_from_line.index(max(distance_of_points_from_line))\n",
        "  ErrorRate=int(len(scaled_dfc)*0.05)+1\n",
        "  OptimalSil= sil.index(max(sil[OptimalElbow-ErrorRate:OptimalElbow+ErrorRate]))\n",
        "  return OptimalSil,ErrorRate,OptimalElbow\n",
        "def K_Evaluation():\n",
        "  #Plot\n",
        "  global sse,K_Means_ALG,sil\n",
        "  K_Means_ALG=Optimal_K()\n",
        "  \n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter( y=sse, mode='markers+lines',name=\"Inertia by K\"))\n",
        "  fig.add_vline(x=K_Means_ALG[2],name=\"Longest Distance\",line_color='#00ff00')\n",
        "  fig.add_trace(go.Scatter( y=[sse[0],sse[-1]],x=[0,len(sse)-1], mode='markers+lines',name=\"Line MIN to MAX\"))\n",
        "  fig.add_annotation(dict(font=dict(color='blue',size=15),\n",
        "                                        x=0,\n",
        "                                        y=-0.12,\n",
        "                                        showarrow=False,\n",
        "                                        text=\"Optimal K By Distance= \"+str(K_Means_ALG[2]),\n",
        "                                        textangle=0,\n",
        "                                        xanchor='left',\n",
        "                                        xref=\"paper\",\n",
        "                                        yref=\"paper\"))\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=\"Elbow Test\",\n",
        "      xaxis_title=\"K\",\n",
        "      yaxis_title=\"Inertia\",\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=14,\n",
        "          color=\"RebeccaPurple\"\n",
        "      ),\n",
        "      width=800\n",
        "  )\n",
        "\n",
        "  fig.show()\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter( y=sil, mode='markers+lines',name=\"Inertia by K\"))\n",
        "  fig.add_vline(x=K_Means_ALG[2]-K_Means_ALG[1],line_dash=\"dash\")\n",
        "  fig.add_vline(x=K_Means_ALG[0],line_color=\"#00ff00\")\n",
        "  fig.add_vline(x=K_Means_ALG[2],line_color=\"#ff4040\")\n",
        "  fig.add_vline(x=K_Means_ALG[2]+K_Means_ALG[1],line_dash=\"dash\")\n",
        "  fig.add_annotation(dict(font=dict(color='blue',size=15),\n",
        "                                        x=0,\n",
        "                                        y=-0.12,\n",
        "                                        showarrow=False,\n",
        "                                        text=\"Final Optimal K= \"+str(K_Means_ALG[0]),\n",
        "                                        textangle=0,\n",
        "                                        xanchor='left',\n",
        "                                        xref=\"paper\",\n",
        "                                        yref=\"paper\"))\n",
        "\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=\"Sillhouette Test\",\n",
        "      xaxis_title=\"K\",\n",
        "      yaxis_title=\"Inertia\",\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=14,\n",
        "          color=\"RebeccaPurple\"\n",
        "      ),\n",
        "      width=800\n",
        "  )\n",
        "\n",
        "  fig.show()\n",
        "  return K_Means_ALG[0]\n",
        "  \n",
        "def K_Evaluation_No_Output():\n",
        "  ElbowTest()\n",
        "  SillTest()\n",
        "  x= K_Evaluation()\n",
        "  clear_output()\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kabZIekfm5i5"
      },
      "source": [
        "#**Overall Site's Info**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYhXhGVuWK-Q"
      },
      "source": [
        "## Month names prep\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cpG4gnnB72z0"
      },
      "outputs": [],
      "source": [
        "def Return_Months(list_of_Num):\n",
        "  arr=[]\n",
        "  list_of_Month_Names=[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
        "  for item in list_of_Num:\n",
        "    arr.append(list_of_Month_Names[item-1])\n",
        "  return arr\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR31rlllWW9P"
      },
      "source": [
        "## Max and Min stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "asbmKFsW4Idi"
      },
      "outputs": [],
      "source": [
        "def Site_Find_Info(column,Site_Name):\n",
        "  df_temp=df.copy()\n",
        "  df_temp=df_temp.loc[df_temp['Site_Name'] == Site_Name]\n",
        "  if len(df_temp)<1:\n",
        "    return\n",
        "  max=df_temp[column].iloc[0]\n",
        "  min=df_temp[column].iloc[0]\n",
        "  min_index=0\n",
        "  Max_index=0\n",
        "  for i in range(len(df_temp[column])):\n",
        "    if max< df_temp[column].iloc[i]:\n",
        "      max=df_temp[column].iloc[i]\n",
        "      Max_index=i\n",
        "    if min > df_temp[column].iloc[i]:\n",
        "      min=df_temp[column].iloc[i]\n",
        "      min_index=i\n",
        "  ListMinMAX=[]\n",
        "  df_temp['Year'] = df_temp.apply(lambda x: x.Date.year, axis=1)\n",
        "  df_temp['Month'] = df_temp.apply(lambda x: x.Date.month, axis=1)\n",
        "  for i in range(1,13):\n",
        "    count=0\n",
        "    amount_counted=1\n",
        "    \n",
        "    df_temp2=df_temp.loc[(df_temp['Month'] == i) & (df_temp['Year']< 2020)]\n",
        "    for j in range(len(df_temp2.index)):\n",
        "      amount_counted+=1\n",
        "      count+=df_temp2[column].iloc[j]\n",
        "    ListMinMAX.append((count/amount_counted,i))\n",
        "  heapq.heapify(ListMinMAX)\n",
        "  Final_Max=heapq.nlargest(3, ListMinMAX)\n",
        "  Final_Min=heapq.nsmallest(3, ListMinMAX)\n",
        "  print(\"-------------------------Max and Min Stats of\", column,\"Entries-------------------------\")\n",
        "  print(\"Max \", column,\" Value:\", max,\"-------Date: [\",df_temp[\"Date\"].iloc[Max_index]\\\n",
        "        ,\"]\\nMin \", column,\" Value:\", min,\"-------Date: [\",df_temp[\"Date\"].iloc[min_index],\"]\" )\n",
        "  print(\"Top 3 months by entry of\",column,\": \",Return_Months([items[1] for items in Final_Max])\\\n",
        "        ,\"\\nBottom 3 months by entry of\",column,\": \",Return_Months([items[1] for items in Final_Min]))\n",
        "  print(\"---------------------------------------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3hq-PUgWfz_"
      },
      "source": [
        "## Printing Overall Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NJnjgVl0nx-O"
      },
      "outputs": [],
      "source": [
        "def Site_Info(Name):\n",
        "  clear_output()\n",
        "  global dfc,df\n",
        "  dfc11=dfc.copy()\n",
        "  \n",
        "  name_df=dfc11.loc[Name]\n",
        "  print(\"--------------Site Info:--------------\")\n",
        "  print(bcolors.GREEN,\"Site Name: \",Name,bcolors.RESET)\n",
        "  count=0\n",
        "  for column in dfc.columns:\n",
        "    count+=1\n",
        "    if column !='cluster':\n",
        "      print(\" \",column,\": \", round(name_df[column],2),end='')\n",
        "    if count == 3:\n",
        "      count=0\n",
        "      print(\"\")\n",
        "\n",
        "  Print_Cluster_Info(FindCluster(Name),Name)\n",
        "  \n",
        "  \n",
        "  print(\"--------------Entries Stats--------------\\n\")\n",
        "  Site_Find_Info(\"Total\",Name)\n",
        "  Site_Find_Info(\"Israelis_Count\",Name)\n",
        "  Site_Find_Info(\"Tourists_Count\",Name)\n",
        "\n",
        "\n",
        "  print(\"----------------------------------------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkB0SlAeTYcB"
      },
      "source": [
        "## Specific Date Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Wwo7weGq9J_d"
      },
      "outputs": [],
      "source": [
        "def Seperate_Site(Name,date):\n",
        "  global df5\n",
        "  dfc11=df5.copy()\n",
        "  dfc11=dfc11.loc[dfc11['Site_Name'] == Name]\n",
        "  dfc11=dfc11.loc[dfc11['Date'] == date]\n",
        "  Arr=['Total','Israelis_Count','Tourists_Count','Temperature','is_HeatWave','Is_Summer','is_weekend','pm2.5','nox','so2','pm10']\n",
        "  dfc11=dfc11[Arr]\n",
        "  return dfc11\n",
        "\n",
        "def Search_Site_By_Date(Name,date):\n",
        "  print(\"------------------\")\n",
        "  dfc11=Seperate_Site(Name,date)\n",
        "  print(\"Site Stats in date: %s\"%(date))\n",
        "  for i in range(len(dfc11.columns)):\n",
        "    print(\"[%s: %s]\"%(dfc11.columns[i],dfc11.iloc[0][i] if dfc11.iloc[0][i] % 1 == 0\\\n",
        "                      else round(dfc11.iloc[0][i],2)),end='')\n",
        "  print(\"------------------\")\n",
        "\n",
        "def Enter_Date(Name):\n",
        "  today=np.datetime64('today')\n",
        "  while(True):\n",
        "    clear_output()\n",
        "    year=int(input(\"Enter Year: \"))\n",
        "    month=int(input(\"Enter Month: \"))\n",
        "    day=int(input(\"Enter day: \"))\n",
        "    try:\n",
        "      answer=None\n",
        "      c=1\n",
        "      \n",
        "      \n",
        "      dfc11=Seperate_Site(Name,np.datetime64(datetime.date(year,month, day)))\n",
        "      \n",
        "      if dfc11.empty==True or today<np.datetime64(datetime.date(year,month, day)):\n",
        "        c=2\n",
        "        print(\"wrong entry \\ no data for this date\\n\")\n",
        "        print(bcolors.GREEN, \"  Y\",bcolors.RESET,\" to try again\\n\", bcolors.GREEN,\"ANY\",bcolors.RESET,\"Input to go back\")\n",
        "        print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "        answer=input(\" \")\n",
        "    except Exception as e:\n",
        "      c=2\n",
        "      print(e)\n",
        "      print(bcolors.GREEN, \"\\n  Y\",bcolors.RESET,\" to try again\\n\", bcolors.GREEN,\"ANY\",bcolors.RESET,\"Input to go back\")\n",
        "      print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "      answer=input(\" \")\n",
        "\n",
        "    if answer in ['Y','y']:\n",
        "      continue\n",
        "    if c==1:\n",
        "      Site_Info(Name)\n",
        "      Search_Site_By_Date(Name,np.datetime64(datetime.date(year,month, day)))\n",
        "      return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkEp8th6nDhK"
      },
      "source": [
        "# Data Prep "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cK6_FiInIz3"
      },
      "source": [
        "## Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zNmi3zpQxx5o"
      },
      "outputs": [],
      "source": [
        "#Data prep\n",
        "\n",
        "def Summer (row,y,min):\n",
        "  for i in range(0,y):\n",
        "      if (row['Date'] >=pd.Timestamp(date(min+i, 6, 1)) and row['Date'] < pd.Timestamp(date(min+i, 9, 1))):\n",
        "        return 1  \n",
        "  return 0\n",
        "def Autumn (row,y,min):\n",
        "  for i in range(0,y):\n",
        "      if (row['Date'] >=pd.Timestamp(date(min+i, 9, 1)) and row['Date'] < pd.Timestamp(date(min+i, 12, 1))):\n",
        "        return 1  \n",
        "  return 0\n",
        "def Spring (row,y,min):\n",
        "  for i in range(0,y):\n",
        "      if (row['Date'] >=pd.Timestamp(date(min+i, 4, 1)) and row['Date'] < pd.Timestamp(date(min+i, 6, 1))):\n",
        "        return 1  \n",
        "  return 0\n",
        "def Winter (row,y,min):\n",
        "  for i in range(0,y):\n",
        "      if (row['Date'] >=pd.Timestamp(date(min+i, 12, 1)) and row['Date'] <= pd.Timestamp(date(min+i, 12, 31))) |\\\n",
        "          (row['Date'] >=pd.Timestamp(date(min+i, 1, 1)) and row['Date'] < pd.Timestamp(date(min+i, 4, 1))):\n",
        "        return 1  \n",
        "  return 0\n",
        "def check(row,y,min):\n",
        "  if Summer(row,y,min):\n",
        "    return 3\n",
        "  if Winter(row,y,min):\n",
        "    return 1\n",
        "  if Spring(row,y,min):\n",
        "    return 2\n",
        "  if Autumn(row,y,min):\n",
        "    return 4\n",
        "  return 0\n",
        "def Date_Data_prep():\n",
        "  global df5\n",
        "  df5 = df.copy()\n",
        "  df5['Year'] = df.apply(lambda x: x.Date.year, axis=1)\n",
        "  y=(df5['Year'].max()+1)-2016\n",
        "  min=df5['Year'].min()\n",
        "  df5['Is_Summer']=df5.apply (lambda row: Summer(row,y,min), axis=1)\n",
        "  df5.drop(['index','Unnamed: 0'], axis=1, inplace=True)\n",
        "# df5['Season']=df5.apply (lambda row: check(row,y,min), axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um9PvEZUnTIW"
      },
      "source": [
        "## Choosing Site, prediction and Pollution Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ilH4QbtAEsLL"
      },
      "outputs": [],
      "source": [
        "#Choosing Site , options: Prediction, Feature select\n",
        "def SiteEx(SiteName,b,pred,Year_List):\n",
        "  global df2, predict\n",
        "  predict=pred\n",
        "  df2=df5.copy()\n",
        "  if Year_List is not False:\n",
        "    df2=df2.loc[(df2['Site_Name']==SiteName) & (df2['Year'].isin(Year_List))]\n",
        "  else:\n",
        "    df2=df2.loc[df2['Site_Name']==SiteName]\n",
        "\n",
        "  if b== True:\n",
        "    df2=df2[[pred,'Temperature','is_HeatWave','Is_Summer','is_weekend','pm2.5','nox','so2','pm10']]\n",
        "  else:\n",
        "    df2=df2[['Temperature',pred,'Is_Summer','is_HeatWave','is_weekend']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijpuND4ynuyr"
      },
      "source": [
        "## Splitting to X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3h6zq8XaEIIX"
      },
      "outputs": [],
      "source": [
        "#y=Target feature, X=independent features\n",
        "def XnY(): \n",
        "  global predict, df2,y,X\n",
        "  y=df2[predict]\n",
        "  X=df2.drop(columns=[predict],axis=1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gREqlkV1n3qK"
      },
      "source": [
        "## Plotting Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0m9yS3YTbU0b"
      },
      "outputs": [],
      "source": [
        "#Plotting features\n",
        "def PlotFeatures():\n",
        "  global X,y\n",
        "  print(\"--------------------Site Features--------------------\\n\")\n",
        "  rows=math.ceil( len(X.columns)/3)\n",
        "  cols = 3\n",
        "  fig = make_subplots(rows=rows, cols=cols, shared_yaxes=True )\n",
        "  count=0\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      if count < len(X.columns):\n",
        "        fig.add_trace(go.Scatter(\n",
        "        y=y, \n",
        "        x=X.iloc[:,count],\n",
        "        mode='markers',\n",
        "        marker_color='blue',\n",
        "        marker_size=2.5,\n",
        "        name=X.columns[count]\n",
        "        ),row=i+1, col=j+1\n",
        "      )\n",
        "        \n",
        "        fig.update_xaxes(title_text=X.columns[count], row=i+1, col=j+1)\n",
        "        count+=1\n",
        "      \n",
        "    \n",
        "  fig.update_layout(height=700, width=900,\n",
        "                  title_text=\"\"+predict+\"Entries By Features\")\n",
        "  fig.show()\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cxJgjD3n9Hm"
      },
      "source": [
        "## Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CG4GJrrQc-E0"
      },
      "outputs": [],
      "source": [
        "#Splitting Data to train and test\n",
        "def split():\n",
        "  global X_train,X_test,y_train,y_test,train_df,test_df\n",
        "  X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1357)\n",
        "  train_df = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
        "  test_df = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEplCjsUoMQ0"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dI4nRtkngUvv"
      },
      "outputs": [],
      "source": [
        "#Scaling Test and Train models\n",
        "def scale():\n",
        "  global x_train_scaler, x_test_scaler,y_train_scaler,y_test_scaler,X_train_scaled,X_test_scaled,y_train_scaled,y_test_scaled\n",
        "\n",
        "  x_train_scaler = StandardScaler()\n",
        "  x_test_scaler = StandardScaler()\n",
        "  y_train_scaler = StandardScaler()\n",
        "  y_test_scaler = StandardScaler()\n",
        "\n",
        "  X_train_scaled = x_train_scaler.fit_transform(X_train)\n",
        "  X_test_scaled = x_test_scaler.fit_transform(X_test)\n",
        "  y_train_scaled = y_train_scaler.fit_transform(pd.DataFrame(y_train))\n",
        "  y_test_scaled = y_test_scaler.fit_transform(pd.DataFrame(y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3iTDi_oQ-X"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZn2ZrC1oY99"
      },
      "source": [
        "## Model Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZbXwdymYoljh"
      },
      "outputs": [],
      "source": [
        "# Building model\n",
        "def build_model():\n",
        "  global X_train_scaled,model\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu',\n",
        "                          input_shape=(X_train_scaled.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "  \n",
        "def Generic_build_model(lay,act,ls,met):\n",
        "  global X_train_scaled,model\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(lay[0], activation=act[0],\n",
        "                          input_shape=(X_train_scaled.shape[1],)))\n",
        "  for i in range(1,len(lay)+1):\n",
        "    model.add(layers.Dense(lay[i], activation=act[i]))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss=ls, metrics=[met])\n",
        "  return model\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2LuDBF5ogwi"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-Wprd_UWolgf"
      },
      "outputs": [],
      "source": [
        "#NN on Train Data set With validation, MSE as loss function, MAE as Epochs Metric\n",
        "\n",
        "def TrainNN():\n",
        "  global num_val_samples, model, history,X_train_scaled,y_train_scaled\n",
        "  \n",
        "  K.clear_session()\n",
        "  num_val_samples = len(X_train_scaled) // 4\n",
        "  num_epochs = 10\n",
        "  all_mae_histories = []\n",
        "\n",
        "\n",
        "  val_data = X_train_scaled[0: num_val_samples]\n",
        "  val_targets = y_train_scaled[0: num_val_samples]\n",
        "\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [X_train_scaled[:0],\n",
        "        X_train_scaled[num_val_samples:]],\n",
        "      axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [y_train_scaled[:0],\n",
        "        y_train_scaled[num_val_samples:]],\n",
        "      axis=0)\n",
        "\n",
        "\n",
        "  model = build_model()\n",
        "\n",
        "  history = model.fit(partial_train_data, partial_train_targets,\n",
        "                      validation_data=(val_data, val_targets),\n",
        "                      epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  mae_history = history.history['val_mae']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejlxnlcXoki8"
      },
      "source": [
        "## Plotting MAE and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_Pwn5frWoleV"
      },
      "outputs": [],
      "source": [
        "#Plotting NN MAE per epoch\n",
        "\n",
        "def PlotMAE():\n",
        "  print(\"---------------------MAE---------------------\")\n",
        "  global history\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict[\"mae\"]\n",
        "  val_loss_values = history_dict[\"val_mae\"]\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "  plt.plot(epochs, loss_values, \"bo\", label=\"Training mae\")\n",
        "  plt.plot(epochs, val_loss_values, \"b\", label=\"Validation mae\")\n",
        "  plt.title(\"Training and validation mae\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"mae\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  print(\"\")\n",
        "  \n",
        "\n",
        "#Plotting NN loss per epoch\n",
        "def PlotLoss():\n",
        "  print(\"---------------------Loss------------------------\")\n",
        "  global history\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict[\"loss\"]\n",
        "  val_loss_values = history_dict[\"val_loss\"]\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "  plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "  plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "  plt.title(\"Training and validation loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQqaQ2OEosfo"
      },
      "source": [
        "## Building Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Mtu02FlDolcJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def BuildFinalNN():\n",
        "  import sys\n",
        "  import os\n",
        "  global model,X_test_scaled,y_test_scaled\n",
        "\n",
        "  # old_stdout = sys.stdout # backup current stdout\n",
        "  # sys.stdout = open(os.devnull, \"w\")\n",
        "\n",
        "  model.fit(X_train_scaled, y_train_scaled, epochs=80, batch_size=512)\n",
        "  Test_Mse,Test_Mae = model.evaluate(X_test_scaled, y_test_scaled)\n",
        "  print(\"Test MSE: \",round(Test_Mae,2),\"\\nTest MAE: \",round(Test_Mse,2))\n",
        "\n",
        "\n",
        "  # sys.stdout = old_stdout # reset old stdout\n",
        "\n",
        "\n",
        "def GetBuild():\n",
        "  global model,X_test_scaled,y_test_scaled\n",
        "  Test_Mse,Test_Mae = model.evaluate(X_test_scaled, y_test_scaled)\n",
        "  print(\"Test MSE: \",round(Test_Mae,2),\"\\nTest MAE: \",round(Test_Mse,2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZdpHi2Uo0c1"
      },
      "source": [
        "# **Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaGsZhS2o_x1"
      },
      "source": [
        "## Building model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SWeCm3aegcKh"
      },
      "outputs": [],
      "source": [
        "#Starting MLR or calling existing MLR\n",
        "def MLR():\n",
        "  global lm\n",
        "  lm = LinearRegression() \n",
        "  lm.fit(X_train_scaled,y_train_scaled)    \n",
        "  coeff = lm.coef_[0]\n",
        "  intercept = lm.intercept_[0] \n",
        "  print(\"\\n\\n-----------------REGRESSION EQUATION-----------------\\n\")        \n",
        "  print('Coefficients: \\n', \"coeff =\", coeff , \",  Intercept=\",intercept,\"\\n\" )\n",
        "  print(\"The regression equation is:\" ,\"\\nEntries=\\n\" ,intercept)\n",
        "  for i in range(0,len(coeff)):\n",
        "    print( \"+ \",round(coeff[i],2),\" * \",X.columns[i])\n",
        "\n",
        "\n",
        "def getMLR():\n",
        "  global lm\n",
        "  coeff = lm.coef_[0]\n",
        "  intercept = lm.intercept_[0]  \n",
        "  print(\"\\n\\n-----------------REGRESSION EQUATION-----------------\\n\")         \n",
        "  print('Coefficients: \\n', \"coeff =\", coeff , \",  Intercept=\",intercept,\"\\n\" )\n",
        "  print(\"The regression equation is:\" ,\"\\nEntries=\\n\" ,intercept)\n",
        "  for i in range(0,len(coeff)):\n",
        "    print( \"+ \",round(coeff[i],2),\" * \",X.columns[i])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TODAYPJ3pK13"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_3Qhjjtxhkvl"
      },
      "outputs": [],
      "source": [
        "# Training the model and printing results\n",
        "def TrainPredict():\n",
        "  global train_df,predicted_train,X_train_scaled,y_train_scaler,y_train\n",
        "  fitted_scaled = lm.predict(X_train_scaled) \n",
        "  fitted = y_train_scaler.inverse_transform(fitted_scaled)\n",
        "  predicted_train = round(pd.Series(fitted[:,0], index=y_train.index, name='Predicted_train'),ndigits=2)\n",
        "  train_df = pd.merge(left=train_df, right=predicted_train , left_index=True, right_index=True)\n",
        "  \n",
        "\n",
        "  print(\"\\n-----------------TRAIN MODEL-----------------\\n\")\n",
        "  Orginize_OutPut(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqtYeNGepRj_"
      },
      "source": [
        "## Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sY6g8q_Uijs4"
      },
      "outputs": [],
      "source": [
        "# Testing the model and printing results\n",
        "def TestPredict():\n",
        "  global test_df,predicted_test,X_test_scaled,y_test_scaler,y_test\n",
        "  fitted_scaled = lm.predict(X_test_scaled)\n",
        "  fitted = y_test_scaler.inverse_transform(fitted_scaled)\n",
        "  predicted_test = round(pd.Series(fitted[:,0], index=y_test.index, name='Predicted_test'),ndigits=2)\n",
        "  test_df = pd.merge(left=test_df, right=predicted_test, left_index=True, right_index=True)\n",
        "  print(\"\\n-----------------TEST MODEL-----------------\\n\")\n",
        "  Orginize_OutPut(test_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgMXz0b8pUQs"
      },
      "source": [
        "## Plotting Residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tVRH_T_Pi_do"
      },
      "outputs": [],
      "source": [
        "# Printing How far the prediction is in the Train model and the Test model from the real value\n",
        "def PlotR():\n",
        "  global train_df,test_df\n",
        "  train_df['residuals'] = train_df.Predicted_train - train_df[predict]\n",
        "  test_df['residuals'] = test_df.Predicted_test - test_df[predict]\n",
        "  \n",
        "  fig= go.Figure()\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=train_df.Predicted_train,\n",
        "          y=train_df.residuals,\n",
        "          mode='markers',\n",
        "          name='train residuals',\n",
        "          marker_color='blue',\n",
        "          marker_size=1.5,\n",
        "          marker_line_width=0,\n",
        "      )\n",
        "  )\n",
        "  fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=test_df.Predicted_test,\n",
        "        y=test_df.residuals,\n",
        "        mode='markers',\n",
        "        name='test residuals',\n",
        "        marker_color='red',\n",
        "        marker_size=1.5,\n",
        "        marker_line_width=0,\n",
        "    )\n",
        "  )\n",
        "  fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=test_df.Predicted_test,\n",
        "        y=test_df.residuals*0,\n",
        "        mode='lines',\n",
        "        name='zero line',\n",
        "        marker_color='black',\n",
        "        marker_size=1.5,\n",
        "        marker_line_width=0,\n",
        "    )\n",
        "  )\n",
        "  fig.update_layout(\n",
        "      title=\"Residuals of Predicted Entries\",\n",
        "      xaxis_title=\"Predicted Entries\",\n",
        "      yaxis_title=\"Residuals\",\n",
        "      font=dict(\n",
        "          size=14,\n",
        "          color=\"RebeccaPurple\"\n",
        "      )\n",
        "  )\n",
        "  fig.show()\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WypcnrkSpcQT"
      },
      "source": [
        "## Regression Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0nu4VqoNi_Mc"
      },
      "outputs": [],
      "source": [
        "#Cost Function and R2\n",
        "def TrainCost():\n",
        "  global predict\n",
        "  print(\"------ TRAIN DATA ------\")\n",
        "  print(\"MSE:\",round(metrics.mean_squared_error(train_df[predict], train_df.Predicted_train),2))\n",
        "  print(\"RMSE:\",round(np.sqrt(metrics.mean_squared_error(train_df[predict], train_df.Predicted_train)),2))\n",
        "  print(\"MAE:\",round(metrics.mean_absolute_error(train_df[predict], train_df.Predicted_train),2),\"\\n\")\n",
        "def TestCost():\n",
        "  global predict\n",
        "  print(\"------ TEST DATA ------\")\n",
        "  print(\"MSE:\",round(metrics.mean_squared_error(test_df[predict], test_df.Predicted_test),2))\n",
        "  print(\"RMSE:\",round(np.sqrt(metrics.mean_squared_error(test_df[predict], test_df.Predicted_test)),2))\n",
        "  print(\"MAE:\",round(metrics.mean_absolute_error(test_df[predict], test_df.Predicted_test),2),\"\\n\") \n",
        "def R2():\n",
        "  global predict\n",
        "  print(\"------ R2 Score ------ \\n\", round(r2_score(train_df[predict], train_df.Predicted_train),2),\"\\n\")\n",
        "def STD():\n",
        "  # Based on STD formula ((âˆ‘(Yâˆ’Yp)^2) /(n-2)) ^0.5 \n",
        "  # https://www.investopedia.com/terms/r/residual-standard-deviation.asp\n",
        "  global predict,train_df,test_df\n",
        "  def STD_Each(df,S):\n",
        "    count=0\n",
        "    if S=='Test':\n",
        "      Name=\"Predicted_test\"\n",
        "    if S=='Train':\n",
        "      Name=\"Predicted_train\"\n",
        "      \n",
        "    for index, row in df.iterrows():\n",
        "      count+=1\n",
        "      sum=pow((row[Name]-row[predict]),2)\n",
        "    if count>2:\n",
        "      STD_R=pow((sum/(count-2)),0.5)\n",
        "      print(\"------\",S,\"STD Error ------\\n\", round(STD_R,2),\"\\n\")\n",
        "  STD_Each(train_df,\"Train\")\n",
        "  STD_Each(test_df,\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PrOC3GXp_PH"
      },
      "source": [
        "# **Backend** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVwPzCEipoWk"
      },
      "source": [
        "## Save,use or replace models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KFl0lcsqXU3_"
      },
      "outputs": [],
      "source": [
        "#saving, getting and using MLRs\n",
        "\n",
        "def save(SiteName,Pol,Predict_Choice,years,date,Model_type):\n",
        "  global test_df,train_df,lm,X,y,predict,model,history,x_train_scaler,y_test_scaled,X_test_scaled\n",
        "  array1=[SiteName,Pol,Predict_Choice,date,years]\n",
        "  array2=[]\n",
        "  if Model_type=='MLR':\n",
        "    array2=[test_df,train_df,X,y,lm,x_train_scaler]\n",
        "  if Model_type =='NN':\n",
        "    array2=[test_df,train_df,X,y,model,history,x_train_scaler,X_test_scaled,y_test_scaled]\n",
        "  return [array1,array2]\n",
        "\n",
        "def replace(k, Store2,Model_type): \n",
        "  global test_df,train_df,lm,X,y,predict,model,history,x_train_scaler,y_test_scaled,X_test_scaled,Model_Index\n",
        "  Store=Store2.copy()\n",
        "  test_df = Store[k][1][0]\n",
        "  train_df=Store[k][1][1]\n",
        "  predict=Store[k][0][2] \n",
        "  X=Store[k][1][2]\n",
        "  y=Store[k][1][3]\n",
        "  Model_Index=k\n",
        "\n",
        "  if Model_type=='MLR':\n",
        "    lm=Store[k][1][4]\n",
        "    x_train_scaler=Store[k][1][5]\n",
        "    \n",
        "\n",
        "    \n",
        "  if Model_type =='NN':\n",
        "    model=Store[k][1][4]\n",
        "    history=Store[k][1][5]\n",
        "    x_train_scaler=Store[k][1][6]\n",
        "    X_test_scaled=Store[k][1][7]\n",
        "    y_test_scaled=Store[k][1][8]\n",
        "    \n",
        "def use(Model_type):\n",
        "  global test_df,train_df,Model_Index\n",
        "  PlotFeatures()\n",
        "  key=Model_Index\n",
        "  if Model_type=='MLR':\n",
        "    \n",
        "    print(\"\\n-----------------TRAIN MODEL-----------------\\n\")\n",
        "    Orginize_OutPut(train_df)\n",
        "    print(\"\\n-----------------TEST MODEL-----------------\\n\")\n",
        "    Orginize_OutPut(test_df)\n",
        "    getMLR()\n",
        "    PlotR()\n",
        "    TrainCost()\n",
        "    TestCost()\n",
        "    R2()\n",
        "    STD()\n",
        "  if Model_type =='NN':\n",
        "    PlotMAE()\n",
        "    PlotLoss()\n",
        "    GetBuild()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo91Y1AaqR-g"
      },
      "source": [
        "## **Running Clustering functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2sb9L7B6pmXi"
      },
      "outputs": [],
      "source": [
        "def Cluster_Run(): \n",
        "  ClusterScale()\n",
        "  Cluster()\n",
        "  global Clustering, Clusters_List,cluster_means,labels,K_means\n",
        "  Clustering={'Clusters_List':Clusters_List,'cluster_means':cluster_means,'cluster_labels':labels, 'K_means':K_means}\n",
        "\n",
        "  \n",
        "def P_Clusters():\n",
        "  clear_output()\n",
        "  print(\"-------------------------Clustering Stats-------------------------\\n\")\n",
        "  ElbowTest()\n",
        "  SillTest()\n",
        "  Clustering_Model_Details()\n",
        "  print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "def ClusterChooseK(K):\n",
        "  global K_means\n",
        "  K_means=K\n",
        "  Cluster_Run()\n",
        "\n",
        "def ClusterReplace():\n",
        "  global Clustering, Clusters_List,cluster_means,labels,K_means\n",
        "  K_means=Clustering[\"K_means\"]\n",
        "  cluster_means=Clustering[\"cluster_means\"]\n",
        "  Clusters_List=Clustering[\"Clusters_List\"]\n",
        "  labels=Clustering[\"cluster_labels\"]\n",
        "\n",
        "def ClusterFind(Name):\n",
        "  Print_Cluster_Info(FindCluster(Name),Name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW84XNiKqer8"
      },
      "source": [
        "## **Starting models, saving locally**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hJYLPiPkHtA8"
      },
      "outputs": [],
      "source": [
        "#Calling Functions and saving to MLRs\n",
        "def start(SiteName,Pol,Predict_Choice,years,Model_type):\n",
        "  SiteEx(SiteName,Pol,Predict_Choice,years)\n",
        "  XnY()\n",
        "  \n",
        "  split()\n",
        "  scale()\n",
        "  if Model_type=='MLR':\n",
        "    PlotFeatures()\n",
        "    MLR()\n",
        "    TrainPredict()\n",
        "    TestPredict()\n",
        "    PlotR()\n",
        "    TrainCost()\n",
        "    TestCost()\n",
        "    R2()\n",
        "    STD()\n",
        "\n",
        "  if Model_type=='NN':\n",
        "    build_model()\n",
        "    TrainNN()\n",
        "    BuildFinalNN()\n",
        "    clear_output()\n",
        "    print(\"\\n\\n >>>>>>>>>>>>  NN Details  <<<<<<<<<<<< \\n\\nSite: %s| Prediction By: %s | Pollution Variables: %s\\n\" %(SiteName,Predict_Choice,Pol))\n",
        "    PlotFeatures()\n",
        "    GetBuild()\n",
        "    PlotMAE()\n",
        "    PlotLoss()\n",
        "    \n",
        "\n",
        "#Checking if MLR was already done with the same parameters\n",
        "def StartAndSave(SiteName,Pol,Predict_Choice,years,Model_type):\n",
        "  global MLRs,NNs,Model_Index\n",
        "\n",
        "  ins=0\n",
        "  if Model_type=='MLR':\n",
        "    for key in MLRs:\n",
        "      if MLRs[key][0][0]==SiteName and MLRs[key][0][1]==Pol and MLRs[key][0][2]==Predict_Choice and MLRs[key][0][4]== years:\n",
        "        print(\"Linear Regression based on this info was already built at %s!\" %(MLRs[key][0][3]))\n",
        "        check = input(\"\\nTo Use the current MLR press Y, to overwrite the current MLR press X\")\n",
        "        if check in [True,1,'Y','y']:\n",
        "          replace(key,MLRs,\"MLR\")\n",
        "          use(\"MLR\")\n",
        "        else:\n",
        "          start(SiteName,Pol,Predict_Choice,years,\"MLR\")\n",
        "          MLRs.update({key:save(SiteName,Pol,Predict_Choice,years,date.today().strftime(\"%d/%m/%Y\"),'MLR')})\n",
        "        ins=1\n",
        "      \n",
        "    if ins==0:\n",
        "      start(SiteName,Pol,Predict_Choice,years,'MLR')\n",
        "      MLRs.update({str(len(MLRs)+1):save(SiteName,Pol,Predict_Choice,years,date.today().strftime(\"%d/%m/%Y\"),'MLR')})\n",
        "      Model_Index=str(len(MLRs))\n",
        "\n",
        "\n",
        "  if Model_type=='NN':\n",
        "    for key in NNs:\n",
        "      if NNs[key][0][0]==SiteName and NNs[key][0][1]==Pol and NNs[key][0][2]==Predict_Choice and NNs[key][0][4]== years:\n",
        "        print(\"Neural Network based on this info was already built at %s!\" %(NNs[key][0][3]))\n",
        "        check = input(\"\\nTo Use the current Neural Network press Y, to overwrite the current Neural Network press X\")\n",
        "        if check in [True,1,'Y','y']:\n",
        "          replace(key,NNs,\"NN\")\n",
        "          use(\"NN\")\n",
        "        else:\n",
        "          start(SiteName,Pol,Predict_Choice,years,'NN')\n",
        "          NNs.update({key:save(SiteName,Pol,Predict_Choice,years,date.today().strftime(\"%d/%m/%Y\"),'NN')})\n",
        "        ins=1\n",
        "      \n",
        "    if ins==0:\n",
        "      start(SiteName,Pol,Predict_Choice,years,'NN')\n",
        "      NNs.update({str(len(NNs)+1):save(SiteName,Pol,Predict_Choice,years,date.today().strftime(\"%d/%m/%Y\"),'NN')})\n",
        "      Model_Index=str(len(NNs))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKP0iICBIGBo"
      },
      "source": [
        "## **Cryptography**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uki7pXBYIUgP"
      },
      "source": [
        "### **Get Key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "i6XA8GtcICCu"
      },
      "outputs": [],
      "source": [
        "def Get_Key():\n",
        "  user='talfx'\n",
        "  pao='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'\n",
        "\n",
        "  github_session = requests.Session()\n",
        "  github_session.auth = (user, pao)\n",
        "\n",
        "  # providing raw url to download csv from github\n",
        "  csv_url1 = 'https://raw.githubusercontent.com/talfx/Final-Project/a33b36c4e4b4ba28b72cdf55fc2ce26102950523/filekey.key'\n",
        "\n",
        "  return github_session.get(csv_url1).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBiODbKiIezW"
      },
      "source": [
        "### **Encrypt Save File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "stV8qj36Id_h"
      },
      "outputs": [],
      "source": [
        "def Encrypt_Save_File():\n",
        "  with open('Models.pkl', 'rb') as file:\n",
        "      original = file.read()\n",
        "  fernet = Fernet(Get_Key())       \n",
        "  encrypted = fernet.encrypt(original)\n",
        "  os.remove('Models.pkl')\n",
        "  with open('Models.pkl', 'wb') as encrypted_file:\n",
        "    encrypted_file.write(encrypted)\n",
        "  return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4KuisEsKUHM"
      },
      "source": [
        "### **Decrypt Save File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GCxkBa7qKTPM"
      },
      "outputs": [],
      "source": [
        "def Decrypt_Save_File(Uploaded_Name):\n",
        "  fernet = Fernet(Get_Key())\n",
        "  with open(Uploaded_Name, 'rb') as enc_file:\n",
        "    encrypted = enc_file.read()\n",
        "  os.remove(Uploaded_Name)\n",
        "  decrypted = fernet.decrypt(encrypted)\n",
        "  with open(Uploaded_Name, 'wb') as dec_file:\n",
        "      dec_file.write(decrypted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_khVEKCcqx1T"
      },
      "source": [
        "### **Saving Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ag7N60t2fRMK"
      },
      "outputs": [],
      "source": [
        "def Save_All():\n",
        "  global MLRs, NNs,Clustering,pao\n",
        "  Models=[MLRs,NNs,Clustering,pao]\n",
        "  with open('Models.pkl', 'wb') as f:\n",
        "    pickle.dump(Models, f)\n",
        "  Encrypt_Save_File()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFDrI7Gq4fP"
      },
      "source": [
        "### **Uploading Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RNoPyLbN6pkH"
      },
      "outputs": [],
      "source": [
        "def Upload_All():\n",
        "  global pao,MLRs,NNs,Clustering\n",
        "  try:\n",
        "    c=0\n",
        "    print(\"\\n--------------Upload a Save---------------\\n\\n\")\n",
        "    my_file = Path(\"Models.pkl\")\n",
        "    if my_file.is_file():\n",
        "      os.remove(\"Models.pkl\")\n",
        "    up = files.upload()\n",
        "    Uploaded_Name=list(up.keys())[0]\n",
        "    Decrypt_Save_File(Uploaded_Name)\n",
        "    with open(Uploaded_Name, 'rb') as f: \n",
        "      \n",
        "      loaded_dict = pickle.load(f)\n",
        "      if loaded_dict[3] != pao:\n",
        "        os.remove(Uploaded_Name)\n",
        "        return False\n",
        "      os.rename(Uploaded_Name, \"Models.pkl\")\n",
        "      MLRs=loaded_dict[0]\n",
        "      NNs=loaded_dict[1]\n",
        "      Clustering=loaded_dict[2]\n",
        "      ClusterReplace()\n",
        "      Encrypt_Save_File()\n",
        "      if Encrypt_Save_File():\n",
        "        return True\n",
        "      return False\n",
        "  \n",
        "  except Exception as e:\n",
        "    try:\n",
        "      if Path(Uploaded_Name).is_file():\n",
        "        os.remove(Uploaded_Name)\n",
        "    except Exception as e:\n",
        "      return e,False\n",
        "    return e,False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql_-A1EbrqY6"
      },
      "source": [
        "# **Frontend**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I0zW7wcrFYV"
      },
      "source": [
        "## Prediction Entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Wjyd5dFHBVHH"
      },
      "outputs": [],
      "source": [
        "#Get Input From The User For Prediction\n",
        "def PredInput():\n",
        "  clear_output()\n",
        "  print(\"---------Enter Inputs---------\")\n",
        "  Feature=[]\n",
        "  for i in X.columns:\n",
        "    \n",
        "    if(i!='Season'):\n",
        "      s=float(input(\"\\n  Enter %s \" %(i)))\n",
        "      \n",
        "    else:\n",
        "      s= float(input(\"\\n  Enter Month \"))\n",
        "      if (s<13 and s >0):\n",
        "        if (s >= 6 and s <  9):\n",
        "          s=3 \n",
        "        if (s >= 9 and s <  11):\n",
        "          s=4  \n",
        "        if (s >=11 and s <=  12) or (s<4 and s>0):\n",
        "          s=1\n",
        "        if (s >= 4 and s < 6):\n",
        "          s=2\n",
        "    \n",
        "    while not (s<50 and s>-20) and i=='Temperature'  :\n",
        "      clear_output()\n",
        "      print(\"  Wrong Entry: must be between -20 and 50\")\n",
        "      s= float(input(\"\\n  Enter %s \" %(i)))\n",
        "\n",
        "    while not (s<13 and s >0) and i=='Season' :\n",
        "      clear_output()\n",
        "      print(\"  Wrong Entry: Must be between 1-12\")\n",
        "      s= float(input(\"\\n  Enter Month \"))\n",
        "      if (s<13 and s >0):\n",
        "        if (s >= 6 and s <  9):\n",
        "          s=3 \n",
        "        if (s >= 9 and s <  11):\n",
        "          s=4  \n",
        "        if (s >=11 and s <=  12) or (s<4 and s>0):\n",
        "          s=1\n",
        "        if (s >= 4 and s < 6):\n",
        "          s=2\n",
        "        \n",
        "    while (s!=1 and s!=0) and( i=='is_weekend' or i=='is_HeatWave' or i=='Is_Summer'):\n",
        "      clear_output()\n",
        "      print(\"  Wrong Entry: Must be 0 or 1\")\n",
        "      s= float(input(\"  Enter %s \" %(i)))\n",
        "     \n",
        "    Feature.append(s)\n",
        "\n",
        "  return Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Halt2uauqn3C"
      },
      "source": [
        "## **Predicting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mBP0aYFaKZDV"
      },
      "outputs": [],
      "source": [
        "#Predicting based on a new entry\n",
        "def PredictX(arr,Model_type):\n",
        "  clear_output()\n",
        "  use(Model_type)\n",
        "  global dfPred,model,lm\n",
        "  dfpred = pd.DataFrame([arr], columns=list(X.columns))\n",
        "  NewXpred=None\n",
        "  NewX_Scaled = x_train_scaler.inverse_transform(dfpred)\n",
        "  if Model_type=='NN':\n",
        "    NewXpred = model.predict(NewX_Scaled)\n",
        "    print(\"---------------Predicting With Neural Network-----------\")\n",
        "  if Model_type=='MLR':\n",
        "    NewXpred = lm.predict(NewX_Scaled)\n",
        "    print(\"---------------Predicting With Multiply Linear Regression-----------\")\n",
        "\n",
        "  print(\"---------------Predicting By----------- \\n\"+dfpred.to_string(index=False))\n",
        "  if(NewXpred[0][0]<0):\n",
        "    print(\"\\n---------------Predicted value---------------\\n\",0)\n",
        "  else:\n",
        "    print(\"---------------Predicted value---------------\\n\",round(NewXpred[0][0]//1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5tgMhkAr7qw"
      },
      "source": [
        "## **Print Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qVECEdqiqyI1"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Printing Functions\n",
        "\n",
        "def Hello():\n",
        "  print(\"------------------------------\",bcolors.CYAN,\"Start\",bcolors.RESET,\\\n",
        "        \"------------------------------------\\n\")\n",
        "  print(\"Welcome To The Main Project!\\n\")\n",
        "  print(\"Title: Nature Reserves in Israel\\n\")\n",
        "  print(\"Target: Predictions, Recommendations and Presenting Data\\n\")\n",
        "  print(\"Project Made by Tal Golan\\n\")\n",
        "  \n",
        "\n",
        "def initial():\n",
        "  print(\"------------------------------\",bcolors.CYAN,\"Lets Start!\",bcolors.RESET,\\\n",
        "        \"------------------------------------\\n\")\n",
        "  print(\"Welcome!\\n\")\n",
        "  print(\"Title: Data Analysis\\n\")\n",
        "  print(\"Models: Learning Your Data And Creating Linear Regression, Neural Network, and Clustering Models\")\n",
        "  print(\"Target: Predictions, Recommendations and Presenting Data\\n\")\n",
        "  print(\"Project Made by Tal Golan\\n\")\n",
        "  \n",
        "\n",
        "def PrintSample():\n",
        "  global df5\n",
        "  print(\"------------------------------\",bcolors.CYAN,\"Data Sample\",bcolors.RESET,\\\n",
        "        \"------------------------------------\\n\")\n",
        "  print(df5.sample(10).to_markdown(),\"\\n\")\n",
        "\n",
        "def PrintIndexes(Model_Type):\n",
        "  global MLRs,NNs\n",
        "  if Model_Type=='MLR':\n",
        "      print(\"There Are \",bcolors.CYAN,\"%d \"%(len(MLRs)),bcolors.RESET,\"Regressions already done:\\n\" )\n",
        "      for key in MLRs:\n",
        "        print(\"Index:\",bcolors.GREEN,\"%s\"% key ,bcolors.RESET,\"Site Name: %s [Pollution Prediction: %s][Prediction By: %s][By Years: %s][Date Created: %s]\\n\" %(MLRs[key][0][0],MLRs[key][0][1],MLRs[key][0][2],MLRs[key][0][4],MLRs[key][0][3]))\n",
        "  if Model_Type=='NN':\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"There Are\",bcolors.CYAN,\" %d\" %(len(NNs)) ,bcolors.RESET,\" Neural Networks already done:\\n\" )\n",
        "    for key in NNs:\n",
        "      print(\"Index:\",bcolors.GREEN,\"%s\" %key ,bcolors.RESET,\"Site Name: %s [Pollution Prediction: %s][Prediction By: %s][By Years: %s][Date Created: %s]\\n\" %(NNs[key][0][0],NNs[key][0][1],NNs[key][0][2],NNs[key][0][4],NNs[key][0][3]))\n",
        "\n",
        "def PrintSites():\n",
        "  global df5\n",
        "  print(\"\\n--------------Sites--------------\\n\")\n",
        "  Names=list(df5['Site_Name'].unique())\n",
        "  for i in range(0,len(Names)):\n",
        "    print(\"[\"+Names[i]+\"]\",end =\" \")\n",
        "    if(i%10==0 and i!=0):\n",
        "      print(\"\\n\")\n",
        "  print(\"\\n---------------------------------\\n\")\n",
        "\n",
        "def AskSiteName():\n",
        "  global df5\n",
        "  while True:\n",
        "    PrintSites()\n",
        "    old_stdout = sys.stdout\n",
        "    print(\">>>>>>>>>>>>     <<<<<<<<<<<<\\n\")\n",
        "    print(bcolors.GREEN, \"<Site Name>\",bcolors.RESET,\": Build the model based on this site\"\\\n",
        "          ,bcolors.GREEN,\"\\n  B\",bcolors.RESET,\": back\\n\")\n",
        "    print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "    Entered= input(\" \")\n",
        "    sys.stdout = old_stdout\n",
        "    if Entered in['b','B']:\n",
        "      return 'Back'\n",
        "      \n",
        "    if Entered in list(df5['Site_Name'].unique()):\n",
        "      clear_output()\n",
        "      return Entered\n",
        "\n",
        "    print(\"-----------------Wrong Entry!-----------------\")\n",
        "\n",
        "def Print_Years(Name):\n",
        "  global df5,All_Years\n",
        "  df6=df5.copy()\n",
        "  df6=df6.loc[df5['Site_Name']==Name]\n",
        "  All_Years=list(df6['Year'].unique())\n",
        "  \n",
        "  print(\"\\n---------------Years By Entry-----------------\\n\")\n",
        "  for i in range(0,len(All_Years)):\n",
        "    print(\"[\"+str(All_Years[i])+\"]\",end =\" \")\n",
        "    if(i%10==0 and i!=0):\n",
        "      print(\"\\n\")\n",
        "  print(\"\\n----------------------------------------------\\n\")\n",
        "\n",
        "def AskYears(Name):\n",
        "    global df6,All_Years\n",
        "    c=1\n",
        "    while True:  \n",
        "      Print_Years(Name)\n",
        "      print(bcolors.GREEN, \"<Year>\",bcolors.RESET,\": Build the model based on year\"\\\n",
        "            ,bcolors.GREEN,\"\\n  A\",bcolors.RESET,\": All\\n\")\n",
        "      if c==0:\n",
        "        print(\"----------Wrong Entry!----------\")\n",
        "        c=1\n",
        "      Entered= list(map(str,input(\"Enter: (Seperate with space to enter multiple years)\\n\").split()))\n",
        "      for item in Entered:\n",
        "        if item in ['a','A']:\n",
        "         return All_Years\n",
        "      All_Years2 = ''.join(str(x) for x in All_Years)\n",
        "      for item in Entered: \n",
        "        if item not in All_Years2:\n",
        "          c=0\n",
        "          break\n",
        "\n",
        "      if c==0:\n",
        "        clear_output()\n",
        "        continue\n",
        "      Entered2 = [ int(x) for x in Entered ]\n",
        "      return Entered2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBRtseH3sIu9"
      },
      "source": [
        "## Interface Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pao8ssRw7YK"
      },
      "source": [
        "### Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9FVVZpshwj-t"
      },
      "outputs": [],
      "source": [
        "def StartR():\n",
        "  global MLRs,NameEntered\n",
        "  c=0\n",
        "  while True:\n",
        "    clear_output()\n",
        "    PrintIndexes(\"MLR\")\n",
        "    print(bcolors.GREEN,\"\\n   Y\",bcolors.RESET,\": Starting New Linear Regression\\n\",\\\n",
        "                    bcolors.GREEN,\"<Index>\",bcolors.RESET,\": Use Existing Linear Regression\\n\"\\\n",
        "                    ,bcolors.GREEN,\" B\",bcolors.RESET,\\\n",
        "                    \": Back\\n\")\n",
        "    if c!=0:\n",
        "      print(\"-----------------Wrong Entry!-----------------\")\n",
        "    print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "    Entered= input(\" \")\n",
        "    clear_output()\n",
        "    if Entered in ['Y','y']:\n",
        "      Name=AskSiteName()\n",
        "      NameEntered=Name\n",
        "      if Name=='Back':\n",
        "        return 'Back'\n",
        "      choice_input(\"MLR\",Name)\n",
        "      return 'R'\n",
        "    if Entered in MLRs.keys():\n",
        "      print(\"\\n\\n >>>>>>>>>>>>>>>>>>>>>>>>  Linear Regression Details  <<<<<<<<<<<<<<<<<<<<<<<< \\n\\nSite: %s | Prediction By: %s | Pollution Variables: %s| By Years: %s\\n\" \\\n",
        "            %(MLRs[Entered][0][0],MLRs[Entered][0][2],MLRs[Entered][0][1],MLRs[Entered][0][4] )) \n",
        "      replace(Entered,MLRs,\"MLR\")\n",
        "      use(\"MLR\") \n",
        "      NameEntered=MLRs[Entered][0][0]\n",
        "      return 'R'\n",
        "    if Entered in['b','B']:\n",
        "      return 'Back'\n",
        "    c+=1\n",
        "    if c==10:\n",
        "      return 'Back'\n",
        "    \n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyRL7dKzxCAk"
      },
      "source": [
        "###Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c7Xsy0IPwmRW"
      },
      "outputs": [],
      "source": [
        "def StartN():\n",
        "  global NNs,NameEntered\n",
        "  c=0\n",
        "  while True:\n",
        "    clear_output()\n",
        "    PrintIndexes(\"NN\")\n",
        "    print(bcolors.GREEN,\"\\n   Y\",bcolors.RESET,\": Starting New Neural Network\\n\",\\\n",
        "                    bcolors.GREEN,\"<Index>\",bcolors.RESET,\": Use Existing Neural Network\\n\"\\\n",
        "                    ,bcolors.GREEN,\" B\",bcolors.RESET,\" Back\")\n",
        "    if c!=0:\n",
        "      print(\"-----------------Wrong Entry!-----------------\")\n",
        "    print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "    Entered= input(\" \")\n",
        "    clear_output()\n",
        "    if Entered in ['Y','y']:\n",
        "      Name=AskSiteName()\n",
        "      NameEntered=Name\n",
        "      if Name=='Back':\n",
        "        return 'Back'\n",
        "      choice_input(\"NN\",Name)\n",
        "      return 'N'\n",
        "\n",
        "    if Entered in NNs.keys():\n",
        "      \n",
        "      print(\"\\n\\n >>>>>>>>>>>>>>>>>>>>>>>>  Neural Network Details  <<<<<<<<<<<<<<<<<<<<<<<< \\n\\nSite: %s | Prediction By: %s | Pollution Variables: %s\\n | Years: %s\\n\" \\\n",
        "            %(NNs[Entered][0][0],NNs[Entered][0][2],NNs[Entered][0][1],NNs[Entered][0][4])) \n",
        "      replace(Entered,NNs,\"NN\")\n",
        "      use(\"NN\") \n",
        "      NameEntered=NNs[Entered][0][0]\n",
        "      return 'N'\n",
        "    if Entered in['b','B']:\n",
        "      return 'Back'\n",
        "    c+=1\n",
        "    if c==10:\n",
        "      return 'Back'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQGPPLgwxHXE"
      },
      "source": [
        "### Prediction Choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5mUxuK6qwo7g"
      },
      "outputs": [],
      "source": [
        "\n",
        "def choice_input(Model_Type,Name):\n",
        "  c=0\n",
        "  while True:\n",
        "    print(\"Which feature to predict? \")\n",
        "    print(bcolors.GREEN,\"\\n  1\",bcolors.RESET,\": Total\\n\",\\\n",
        "                    bcolors.GREEN,\"2\",bcolors.RESET,\": Local\\n\"\\\n",
        "                    ,bcolors.GREEN,\"3\",bcolors.RESET,\\\n",
        "                    \": Tourists\\n\")\n",
        "    if c==1:\n",
        "      print(\"--------Wrong Entry!-----------\\n\")\n",
        "      \n",
        "    Predict1= input(\" \")\n",
        "    clear_output()\n",
        "\n",
        "    if Predict1 == '1':\n",
        "      Predict='Total'\n",
        "      break\n",
        "\n",
        "    if Predict1 == '2':\n",
        "      Predict='Israelis_Count'\n",
        "      break\n",
        "\n",
        "    if Predict1 == '3':\n",
        "      Predict='Tourists_Count'\n",
        "      break\n",
        "\n",
        "    clear_output()\n",
        "    c=1\n",
        "    \n",
        "  print(\"\")\n",
        "  c=0\n",
        "  years=AskYears(Name)\n",
        "  clear_output()\n",
        "  while True:\n",
        "    \n",
        "    print(\"Predict With Pollution Variables?  \"\\\n",
        "                    ,bcolors.GREEN,\"Y/N\",bcolors.RESET)\n",
        "    print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "    if c==1:\n",
        "      print(\"--------Wrong Entry!-----------\\n\")\n",
        "      \n",
        "    Pol= input(\" \")\n",
        "    clear_output()\n",
        "\n",
        "    if Pol in ['Y','y']:\n",
        "      Pol=True\n",
        "      break\n",
        "    if Pol in ['N','n']:\n",
        "      Pol=False\n",
        "      break\n",
        "    c=1\n",
        "    \n",
        "  clear_output()\n",
        "  if Model_Type==\"MLR\":\n",
        "    print(\"\\n\\n >>>>>>>>>>>>  MLR Details  <<<<<<<<<<<< \\n\\nSite: %s | Prediction By: %s | Pollution Variables: %s| Years: %s\\n\" %(Name,Predict,Pol,years))\n",
        "    StartAndSave(Name,Pol,Predict,years,\"MLR\")\n",
        "  if Model_Type==\"NN\":\n",
        "    print(\"\\n\\n >>>>>>>>>>>>  NN Details  <<<<<<<<<<<< \\n\\nSite: %s | Prediction By: %s | Pollution Variables: %s| Years: %s\\n\" %(Name,Predict,Pol,years))\n",
        "    StartAndSave(Name,Pol,Predict,years,\"NN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZXnOFjPxVL2"
      },
      "source": [
        "### Nature Reserves Interface num.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RJlmyruxqiNH"
      },
      "outputs": [],
      "source": [
        "def Go_Back():\n",
        "  count=0\n",
        "  print(bcolors.GREEN,\"\\n B\",bcolors.RESET,\":  Back\")\n",
        "  while True:\n",
        "    print(bcolors.GREEN,\"Enter Command:\",bcolors.RESET)\n",
        "    inpt= input(\" \")\n",
        "    if inpt in['B','b']:\n",
        "      return 'back'\n",
        "    if count==10:\n",
        "      return 'back'\n",
        "    count+=1\n",
        "    print(\"Wrong Entry\")\n",
        "\n",
        "def After_Clustering():\n",
        "  global Clusters_List\n",
        "  count=0\n",
        "  c=0\n",
        "  while True:\n",
        "    \n",
        "    print(bcolors.GREEN,\" K\",bcolors.RESET,\":  Change Clustering K-Means\\n\"\\\n",
        "        ,bcolors.GREEN,\"F\",bcolors.RESET,\":  Find The Optimal K-Means\\n\"\\\n",
        "        ,bcolors.GREEN,\"B\",bcolors.RESET,\":  Back\\n\")\n",
        "    \n",
        "    if c==1:\n",
        "      print(\"---------Wrong Entry--------\")\n",
        "      c=0\n",
        "    print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "    inpt= input(\" \")\n",
        "    clear_output()\n",
        "    if inpt in['B','b']:\n",
        "      return 'Back'\n",
        "    if count==10:\n",
        "      return 'Back'\n",
        "    if inpt in['K','k']:\n",
        "      count2=0\n",
        "      c2=0\n",
        "      while True:\n",
        "        print(\" Enter\" ,bcolors.GREEN,\"<K-means>\" ,bcolors.RESET,\":  Build A New Clustering Model\"\\\n",
        "              \"\\n Enter\",bcolors.GREEN,\"B\",bcolors.RESET,\":  Back\" )\n",
        "        print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "\n",
        "        if c2==1:\n",
        "          print(\"--------Wrong Entry!------------\")\n",
        "          c2=0\n",
        "\n",
        "        NewK= input(\" \")\n",
        "        clear_output()\n",
        "        if NewK in ['b','B']:\n",
        "          return 'Back'\n",
        "        try:\n",
        "          NewK= int(NewK)\n",
        "          MaxK=0\n",
        "          for y in [len(x) for x in Clusters_List]:\n",
        "            MaxK+=y\n",
        "          \n",
        "          if NewK>1 and NewK<MaxK:\n",
        "            ClusterChooseK(NewK)\n",
        "            print(\"K-means Updated\")\n",
        "            return 'Updated'\n",
        "        except Exception as e: \n",
        "          print(e)\n",
        "          c2=2\n",
        "          count2+=1\n",
        "          continue\n",
        "        c2=1\n",
        "        count2+=1\n",
        "        if count2==10:\n",
        "          return 'Back'\n",
        "    if inpt in['F','f']:\n",
        "      K_Evaluation()\n",
        "      Sta= input(\"Enter ANY key to continue \")\n",
        "      return 'Back'\n",
        "\n",
        "\n",
        "    count+=1\n",
        "    c=1\n",
        "  \n",
        "\n",
        "def Start_Menu():\n",
        "  global NameEntered\n",
        "  c=0\n",
        "  count=0\n",
        "  while True:\n",
        "    if c !=0:\n",
        "      clear_output()\n",
        "    Hello()\n",
        "    print(\"------------------------------\",bcolors.CYAN,\"Models\",bcolors.RESET,\"------------------------------------\\n\")\n",
        "\n",
        "    print(bcolors.GREEN,\" R\",bcolors.RESET,\":  Linear Regression Prediction\\n\",\\\n",
        "                    bcolors.GREEN,\"N\",bcolors.RESET,\":  Neural Network Prediction\\n\"\\\n",
        "                    ,bcolors.GREEN, \"C\",bcolors.RESET,\":  Clustering Information \\n\",\\\n",
        "                    bcolors.GREEN, \"S\",bcolors.RESET,\":  Site Information and Recommendations\\n\"\\\n",
        "          \n",
        "\n",
        "                    \"--------------------------------\",bcolors.CYAN,\"Project\",bcolors.RESET\\\n",
        "                    ,\"----------------------------------\\n\"\\\n",
        "          \n",
        "                    ,bcolors.GREEN,\"Save\",bcolors.RESET,\":  Save Models\\n\"\\\n",
        "                    ,bcolors.GREEN,\"Upload\",bcolors.RESET,\":  Upload Models (will override current status)\\n\"\\\n",
        "                    ,bcolors.GREEN,\"Sample\",bcolors.RESET,\":  Data Sample\\n\"\\\n",
        "                    ,bcolors.GREEN,\"Reset\",bcolors.RESET,\":  Reset Project (Models Will Be Lost)\\n\"\\\n",
        "                   ,bcolors.GREEN,\"Exit\",bcolors.RESET,\":  Exit\\n\")\n",
        "    \n",
        "\n",
        "    if c==1:\n",
        "      print(\"\\n--------------\",bcolors.CYAN,\"Wrong Entry!\",bcolors.RESET,\"--------------\")\n",
        "      \n",
        "    if c==3:\n",
        "      print(\"\\n---------------\",bcolors.CYAN,\"K-Means Updated!\",bcolors.RESET,\"----------------------\")\n",
        "\n",
        "    if c==5:\n",
        "      print(\"\\n---------------\",bcolors.CYAN,\"Models Saved!\",bcolors.RESET,\"------------------------\")\n",
        "      print(\"\\n--\",bcolors.CYAN,\"(You Can Download The Save File From Colab)\",bcolors.RESET,\"-------\")\n",
        "\n",
        "    if c==6:\n",
        "      print(\"\\n---------------\",bcolors.CYAN,\"Models Uploaded!\",bcolors.RESET,\"------------------------\")\n",
        "\n",
        "    if c==7:\n",
        "      print(\"\\n---------------\",bcolors.CYAN,\"Error Uploading file: batch file/canceled upload\",bcolors.RESET,\"--------------------\")\n",
        "\n",
        "    if c==8:\n",
        "      print(\"\\n---------------\",bcolors.CYAN,\"Project Has Reset Succesfully\",bcolors.RESET,\"------------------------\")\n",
        "      \n",
        "    c=0\n",
        "    if count==10:\n",
        "      return 'Back'\n",
        "    print(bcolors.GREEN,\" Enter Command:\",bcolors.RESET)\n",
        "    Start= input(\"  \")\n",
        "    if Start in['Exit','EXIT','exit']:\n",
        "      return \"Exit\"\n",
        "    clear_output()\n",
        "    Ccheck=0\n",
        "    if Start in['R','r']:\n",
        "      return StartR()\n",
        "    \n",
        "    if Start in['c','C']:\n",
        "      P_Clusters()\n",
        "      After_Cluster=After_Clustering()\n",
        "      if After_Cluster =='Back':\n",
        "        c='clear'\n",
        "        continue\n",
        "      if After_Cluster=='Updated':\n",
        "        c=3\n",
        "        continue\n",
        "      \n",
        "    if Start in['n','N']:\n",
        "      return StartN()\n",
        "    if Start in['s','S']:\n",
        "      \n",
        "      Entered_Site=AskSiteName()\n",
        "      NameEntered=Entered_Site\n",
        "      if Entered_Site =='Back':\n",
        "        c='back'\n",
        "        continue\n",
        "      Site_Info(Entered_Site)\n",
        "      output_info=0\n",
        "      while True:\n",
        "        print(bcolors.GREEN,\"\\n  B\",bcolors.RESET,\":  Go Back\\n\"\\\n",
        "              ,bcolors.GREEN,\"M\",bcolors.RESET,\":  Get Site info by date\\n\")\n",
        "        if output_info==1:\n",
        "          print(\"-----------wrong entry!-----------\")\n",
        "        print(\"\\n\",bcolors.GREEN,\"Enter Command:\",bcolors.RESET)\n",
        "        After_Info= input(\"\")\n",
        "        clear_output()\n",
        "        if After_Info in['B','b']:\n",
        "          Ccheck=1\n",
        "          break\n",
        "        if After_Info in['M','m']:\n",
        "          Enter_Date(Entered_Site)\n",
        "          continue\n",
        "\n",
        "        output_info=1\n",
        "      \n",
        "      if Ccheck==1:\n",
        "        c=4\n",
        "        Ccheck=0\n",
        "        continue\n",
        "    \n",
        "    if Start in ['SAVE','save',\"Save\"]:\n",
        "      Save_All()\n",
        "      c=5\n",
        "      continue\n",
        "    if Start in ['Upload','UPLOAD',\"upload\"]:\n",
        "      if Upload_All() is False:\n",
        "        c=7\n",
        "        continue\n",
        "      c=6\n",
        "      continue\n",
        "    if Start in ['Sample','SAMPLE','sample']:\n",
        "      PrintSample()\n",
        "      Go_Back()\n",
        "      c='clear'\n",
        "      continue\n",
        "    if Start in ['RESET','reset','Reset']:\n",
        "      global MLRs,NNs,Clustering\n",
        "      MLRs={}\n",
        "      NNs={}\n",
        "      c=8\n",
        "      ClusterChooseK(20)\n",
        "      continue\n",
        "\n",
        "    c=1\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu5d-FEmsaB9"
      },
      "source": [
        "### Nature Reserves Interface num.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NYWv1WzjNRtW"
      },
      "outputs": [],
      "source": [
        "#prep functions run\n",
        "def DataPrep_Nature_Reserves():\n",
        "  global Run_Check\n",
        "  if Run_Check==0:\n",
        "    Main_Project()\n",
        "    Starting_Data_Prep_Main()\n",
        "    choice()\n",
        "    Date_Data_prep()\n",
        "  Run_Check=1\n",
        "# Main of Nature Reserves\n",
        "def Execute():\n",
        "  DataPrep_Nature_Reserves()\n",
        "  while True:\n",
        "    Answer=None\n",
        "    global K_means,NameEntered,Clusters_List,Clustering\n",
        "    \n",
        "    try:\n",
        "      if not Clustering:\n",
        "        ClusterChooseK(20)\n",
        "      Answer=Start_Menu()\n",
        "      if Answer=='Exit':\n",
        "        print(\"\\n------------Closed. Run again to continue.------------\")\n",
        "        break\n",
        "      if Answer=='Back':\n",
        "        clear_output()\n",
        "        continue\n",
        "    \n",
        "\n",
        "      def MenuChoice():\n",
        "        \n",
        "        \n",
        "        print(\">>>>>>>>>>>>      Prediction     <<<<<<<<<<<<\\n\")\n",
        "        print(bcolors.GREEN,\"  Y\",bcolors.RESET,\": Predict\",bcolors.GREEN,\"X\",\\\n",
        "                  bcolors.RESET,\": Stop\",bcolors.GREEN,\"B\",bcolors.RESET,\": Back\\n\")\n",
        "        \n",
        "        while(True):\n",
        "          print(bcolors.GREEN,\"\\n Enter Command:\",bcolors.RESET)\n",
        "          Sta= input(\" \")\n",
        "          count=1\n",
        "          if Sta in['b','B'] or count==10:\n",
        "            clear_output()\n",
        "            return 5\n",
        "          if Sta in['x','X']:\n",
        "            return False\n",
        "          if Sta in['y','Y']:\n",
        "            return True\n",
        "          print(\"--------------Wrong Input!--------------\")\n",
        "          count+=1\n",
        "\n",
        "      inputcheck=0\n",
        "      while inputcheck==0:\n",
        "        Nr=MenuChoice()\n",
        "        if Nr == 5:\n",
        "          inputcheck=1\n",
        "          break\n",
        "        if Nr == False:\n",
        "          inputcheck=0\n",
        "          break\n",
        "        if Nr== True:\n",
        "          if Answer=='R':\n",
        "            PredictX(PredInput(),\"MLR\")\n",
        "          if Answer=='N':\n",
        "            PredictX(PredInput(),\"NN\")\n",
        "\n",
        "      if inputcheck==1:\n",
        "        continue\n",
        "      if inputcheck==0:\n",
        "        print(\"\\n------------Closed. Run again to continue.------------\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "      clear_output()\n",
        "      print(e)\n",
        "      try:\n",
        "        Sta= input(\"Enter ANY key to continue \")\n",
        "        clear_output()\n",
        "        continue\n",
        "      except KeyboardInterrupt:\n",
        "        print(bcolors.YELLOW,'Interrupted By Input',bcolors.RESET)\n",
        "        return\n",
        "      \n",
        "    except KeyboardInterrupt:\n",
        "      print(bcolors.YELLOW,'Interrupted By Input',bcolors.RESET)\n",
        "      return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfyEnbGGKwIZ"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yj3G87fLYuY"
      },
      "source": [
        "##Main Project Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A5i2HwBr6fGO",
        "outputId": "c61b3675-b26c-4142-cc24-13dcf7db839e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------ \u001b[96m Start \u001b[0m ------------------------------------\n",
            "\n",
            "Welcome To The Main Project!\n",
            "\n",
            "Title: Nature Reserves in Israel\n",
            "\n",
            "Target: Predictions, Recommendations and Presenting Data\n",
            "\n",
            "Project Made by Tal Golan\n",
            "\n",
            "------------------------------ \u001b[96m Models \u001b[0m ------------------------------------\n",
            "\n",
            "\u001b[92m  R \u001b[0m :  Linear Regression Prediction\n",
            " \u001b[92m N \u001b[0m :  Neural Network Prediction\n",
            " \u001b[92m C \u001b[0m :  Clustering Information \n",
            " \u001b[92m S \u001b[0m :  Site Information and Recommendations\n",
            "-------------------------------- \u001b[96m Project \u001b[0m ----------------------------------\n",
            " \u001b[92m Save \u001b[0m :  Save Models\n",
            " \u001b[92m Upload \u001b[0m :  Upload Models (will override current status)\n",
            " \u001b[92m Sample \u001b[0m :  Data Sample\n",
            " \u001b[92m Reset \u001b[0m :  Reset Project (Models Will Be Lost)\n",
            " \u001b[92m Exit \u001b[0m :  Exit\n",
            "\n",
            "\n",
            "--------------- \u001b[96m Models Saved! \u001b[0m ------------------------\n",
            "\n",
            "-- \u001b[96m (You Can Download The Save File From Colab) \u001b[0m -------\n",
            "\u001b[92m  Enter Command: \u001b[0m\n",
            "  exit\n",
            "\n",
            "------------Closed. Run again to continue.------------\n"
          ]
        }
      ],
      "source": [
        "Execute()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final Project Data Analysis .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}